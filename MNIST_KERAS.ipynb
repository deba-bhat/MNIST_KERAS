{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "dataset = pd.read_csv('mnist_train.csv')\n",
    "X_train = dataset.iloc[:, 1:].values\n",
    "y_train = dataset.iloc[:, 0].values\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "#labelencoder_y = LabelEncoder()\n",
    "#y = labelencoder_y.fit_transform(y)\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "onehotencoder = OneHotEncoder(categorical_features = [0])\n",
    "y_train = onehotencoder.fit_transform(y_train).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deba_bhat12/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "  440/53999 [..............................] - ETA: 1:16 - loss: 0.2666 - acc: 0.9059Epoch 1/10\n",
      " 2980/53999 [>.............................] - ETA: 1:02 - loss: 0.1184 - acc: 0.9589Epoch 1/10\n",
      " 2920/53999 [>.............................] - ETA: 35s - loss: 0.1187 - acc: 0.9573Epoch 1/10\n",
      "  730/53999 [..............................] - ETA: 1:06 - loss: 0.2126 - acc: 0.9266Epoch 1/10\n",
      " 2870/53999 [>.............................] - ETA: 35s - loss: 0.1199 - acc: 0.9592Epoch 1/10\n",
      " 2680/53999 [>.............................] - ETA: 38s - loss: 0.1224 - acc: 0.9582Epoch 1/10\n",
      "53999/53999 [==============================] - 35s 657us/step - loss: 0.0483 - acc: 0.9843\n",
      "53999/53999 [==============================] - 33s 611us/step - loss: 0.0491 - acc: 0.9841\n",
      "Epoch 2/10\n",
      "Epoch 2/10\n",
      "53999/53999 [==============================] - 34s 632us/step - loss: 0.0480 - acc: 0.9841\n",
      "Epoch 2/10\n",
      "53999/53999 [==============================] - 34s 624us/step - loss: 0.0484 - acc: 0.9843\n",
      "52980/53999 [============================>.] - ETA: 0s - loss: 0.0476 - acc: 0.9844Epoch 2/10\n",
      "53999/53999 [==============================] - 34s 631us/step - loss: 0.0475 - acc: 0.9845\n",
      " 4180/53999 [=>............................] - ETA: 29s - loss: 0.0373 - acc: 0.9887Epoch 2/10\n",
      "53999/53999 [==============================] - 33s 614us/step - loss: 0.0474 - acc: 0.9844\n",
      " 4280/53999 [=>............................] - ETA: 29s - loss: 0.0378 - acc: 0.9885Epoch 2/10\n",
      "53999/53999 [==============================] - 34s 630us/step - loss: 0.0475 - acc: 0.9844\n",
      "Epoch 2/10\n",
      "53999/53999 [==============================] - 34s 635us/step - loss: 0.0479 - acc: 0.9844\n",
      "Epoch 2/10\n",
      "53999/53999 [==============================] - 33s 602us/step - loss: 0.0325 - acc: 0.9904\n",
      "45780/53999 [========================>.....] - ETA: 5s - loss: 0.0307 - acc: 0.9908Epoch 3/10\n",
      "53999/53999 [==============================] - 33s 619us/step - loss: 0.0316 - acc: 0.9906\n",
      "50380/53999 [==========================>...] - ETA: 2s - loss: 0.0318 - acc: 0.9905Epoch 3/10\n",
      "53999/53999 [==============================] - 34s 627us/step - loss: 0.0324 - acc: 0.9901\n",
      "51490/53999 [===========================>..] - ETA: 1s - loss: 0.0316 - acc: 0.9903Epoch 3/10\n",
      "53999/53999 [==============================] - 33s 608us/step - loss: 0.0322 - acc: 0.9905\n",
      " 1680/53999 [..............................] - ETA: 31s - loss: 0.0288 - acc: 0.9917Epoch 3/10\n",
      "53999/53999 [==============================] - 34s 624us/step - loss: 0.0317 - acc: 0.9906\n",
      "Epoch 3/10\n",
      "53999/53999 [==============================] - 33s 619us/step - loss: 0.0316 - acc: 0.9903\n",
      " 3990/53999 [=>............................] - ETA: 31s - loss: 0.0267 - acc: 0.9923Epoch 3/10\n",
      "53999/53999 [==============================] - 33s 619us/step - loss: 0.0309 - acc: 0.9907\n",
      "Epoch 3/10\n",
      "53999/53999 [==============================] - 33s 620us/step - loss: 0.0316 - acc: 0.9905\n",
      " 3840/53999 [=>............................] - ETA: 29s - loss: 0.0247 - acc: 0.9922Epoch 3/10\n",
      "53999/53999 [==============================] - 32s 600us/step - loss: 0.0279 - acc: 0.9920\n",
      "Epoch 4/10\n",
      "53999/53999 [==============================] - 33s 615us/step - loss: 0.0276 - acc: 0.9922\n",
      "Epoch 4/10\n",
      "53999/53999 [==============================] - 33s 614us/step - loss: 0.0286 - acc: 0.9918\n",
      " 1360/53999 [..............................] - ETA: 30s - loss: 0.0190 - acc: 0.9948Epoch 4/10\n",
      "53999/53999 [==============================] - 33s 605us/step - loss: 0.0279 - acc: 0.9920\n",
      "52600/53999 [============================>.] - ETA: 0s - loss: 0.0276 - acc: 0.9920Epoch 4/10\n",
      "53999/53999 [==============================] - 32s 602us/step - loss: 0.0280 - acc: 0.9920\n",
      " 2440/53999 [>.............................] - ETA: 31s - loss: 0.0203 - acc: 0.9944Epoch 4/10\n",
      "53999/53999 [==============================] - 33s 609us/step - loss: 0.0277 - acc: 0.9920\n",
      "Epoch 4/10\n",
      "53999/53999 [==============================] - 33s 611us/step - loss: 0.0268 - acc: 0.9921\n",
      "Epoch 4/10\n",
      "53999/53999 [==============================] - 34s 628us/step - loss: 0.0278 - acc: 0.9921\n",
      "11830/53999 [=====>........................] - ETA: 25s - loss: 0.0230 - acc: 0.9935Epoch 4/10\n",
      "53999/53999 [==============================] - 32s 590us/step - loss: 0.0254 - acc: 0.9930\n",
      "40570/53999 [=====================>........] - ETA: 8s - loss: 0.0244 - acc: 0.9933Epoch 5/10\n",
      "53999/53999 [==============================] - 33s 606us/step - loss: 0.0243 - acc: 0.9933\n",
      "Epoch 5/10\n",
      "53999/53999 [==============================] - 33s 609us/step - loss: 0.0256 - acc: 0.9927\n",
      "Epoch 5/10\n",
      "53999/53999 [==============================] - 33s 602us/step - loss: 0.0252 - acc: 0.9931\n",
      " 6170/53999 [==>...........................] - ETA: 28s - loss: 0.0221 - acc: 0.9942Epoch 5/10\n",
      "53999/53999 [==============================] - 33s 611us/step - loss: 0.0246 - acc: 0.9932\n",
      "Epoch 5/10\n",
      "53999/53999 [==============================] - 33s 605us/step - loss: 0.0248 - acc: 0.9931\n",
      "Epoch 5/10\n",
      "53999/53999 [==============================] - 33s 617us/step - loss: 0.0237 - acc: 0.9932\n",
      "Epoch 5/10\n",
      "53999/53999 [==============================] - 33s 616us/step - loss: 0.0241 - acc: 0.9934\n",
      " 6280/53999 [==>...........................] - ETA: 29s - loss: 0.0190 - acc: 0.9948Epoch 5/10\n",
      "53999/53999 [==============================] - 32s 598us/step - loss: 0.0226 - acc: 0.9940\n",
      "Epoch 6/10\n",
      "53999/53999 [==============================] - 34s 631us/step - loss: 0.0227 - acc: 0.9939\n",
      "51430/53999 [===========================>..] - ETA: 1s - loss: 0.0231 - acc: 0.9936Epoch 6/10\n",
      "53999/53999 [==============================] - 34s 621us/step - loss: 0.0227 - acc: 0.9937\n",
      "Epoch 6/10\n",
      "53999/53999 [==============================] - 34s 627us/step - loss: 0.0232 - acc: 0.9936\n",
      "  280/53999 [..............................] - ETA: 31s - loss: 0.0179 - acc: 0.9946Epoch 6/10\n",
      "53999/53999 [==============================] - 34s 629us/step - loss: 0.0219 - acc: 0.9940\n",
      "Epoch 6/10\n",
      "53999/53999 [==============================] - 34s 624us/step - loss: 0.0230 - acc: 0.9937\n",
      "Epoch 6/10\n",
      "53999/53999 [==============================] - 34s 625us/step - loss: 0.0215 - acc: 0.9942\n",
      " 5500/53999 [==>...........................] - ETA: 30s - loss: 0.0205 - acc: 0.9946Epoch 6/10\n",
      "53999/53999 [==============================] - 34s 636us/step - loss: 0.0215 - acc: 0.9944\n",
      " 9360/53999 [====>.........................] - ETA: 27s - loss: 0.0195 - acc: 0.9946Epoch 6/10\n",
      "53999/53999 [==============================] - 32s 592us/step - loss: 0.0211 - acc: 0.9945\n",
      "Epoch 7/10\n",
      "53999/53999 [==============================] - 33s 603us/step - loss: 0.0219 - acc: 0.9941\n",
      "46950/53999 [=========================>....] - ETA: 4s - loss: 0.0207 - acc: 0.9944Epoch 7/10\n",
      "53999/53999 [==============================] - 34s 631us/step - loss: 0.0212 - acc: 0.9945\n",
      "53240/53999 [============================>.] - ETA: 0s - loss: 0.0217 - acc: 0.9944Epoch 7/10\n",
      "53999/53999 [==============================] - 33s 618us/step - loss: 0.0227 - acc: 0.9940\n",
      "Epoch 7/10\n",
      "53999/53999 [==============================] - 33s 607us/step - loss: 0.0217 - acc: 0.9944\n",
      "  580/53999 [..............................] - ETA: 35s - loss: 0.0079 - acc: 0.9978Epoch 7/10\n",
      "53999/53999 [==============================] - 33s 608us/step - loss: 0.0213 - acc: 0.9944\n",
      "11920/53999 [=====>........................] - ETA: 24s - loss: 0.0171 - acc: 0.9953Epoch 7/10\n",
      "53999/53999 [==============================] - 33s 609us/step - loss: 0.0208 - acc: 0.9944\n",
      "Epoch 7/10\n",
      "53999/53999 [==============================] - 34s 621us/step - loss: 0.0205 - acc: 0.9947\n",
      "Epoch 7/10\n",
      "53999/53999 [==============================] - 32s 594us/step - loss: 0.0194 - acc: 0.9949\n",
      "Epoch 8/10\n",
      "53999/53999 [==============================] - 32s 598us/step - loss: 0.0207 - acc: 0.9946\n",
      "Epoch 8/10\n",
      "53999/53999 [==============================] - 33s 613us/step - loss: 0.0199 - acc: 0.9950\n",
      "53999/53999 [==============================] - 33s 612us/step - loss: 0.0206 - acc: 0.9946\n",
      "Epoch 8/10\n",
      "50210/53999 [==========================>...] - ETA: 2s - loss: 0.0189 - acc: 0.9950Epoch 8/10\n",
      "53999/53999 [==============================] - 33s 609us/step - loss: 0.0204 - acc: 0.9947\n",
      "Epoch 8/10\n",
      "53999/53999 [==============================] - 33s 610us/step - loss: 0.0207 - acc: 0.9946\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53999/53999 [==============================] - 32s 596us/step - loss: 0.0191 - acc: 0.9949\n",
      "Epoch 8/10\n",
      "53999/53999 [==============================] - 33s 612us/step - loss: 0.0202 - acc: 0.9948\n",
      "Epoch 8/10\n",
      "53999/53999 [==============================] - 32s 592us/step - loss: 0.0188 - acc: 0.9952\n",
      "40310/53999 [=====================>........] - ETA: 8s - loss: 0.0199 - acc: 0.9952Epoch 9/10\n",
      "53999/53999 [==============================] - 33s 614us/step - loss: 0.0195 - acc: 0.9950\n",
      "51170/53999 [===========================>..] - ETA: 1s - loss: 0.0193 - acc: 0.9951Epoch 9/10\n",
      "53999/53999 [==============================] - 33s 602us/step - loss: 0.0195 - acc: 0.9952\n",
      "Epoch 9/10\n",
      "53999/53999 [==============================] - 33s 610us/step - loss: 0.0187 - acc: 0.9951\n",
      "53999/53999 [==============================] - 33s 605us/step - loss: 0.0193 - acc: 0.9951\n",
      "Epoch 9/10\n",
      "43940/53999 [=======================>......] - ETA: 6s - loss: 0.0193 - acc: 0.9954Epoch 9/10\n",
      "53999/53999 [==============================] - 34s 623us/step - loss: 0.0197 - acc: 0.9949\n",
      " 1560/53999 [..............................] - ETA: 32s - loss: 0.0140 - acc: 0.9964Epoch 9/10\n",
      "53999/53999 [==============================] - 33s 610us/step - loss: 0.0186 - acc: 0.9952\n",
      "Epoch 9/10\n",
      "53999/53999 [==============================] - 33s 618us/step - loss: 0.0192 - acc: 0.9954\n",
      "Epoch 9/10\n",
      "53999/53999 [==============================] - 32s 591us/step - loss: 0.0186 - acc: 0.9953\n",
      "Epoch 10/10\n",
      "53999/53999 [==============================] - 33s 612us/step - loss: 0.0189 - acc: 0.9952\n",
      "Epoch 10/10\n",
      "53999/53999 [==============================] - 33s 607us/step - loss: 0.0183 - acc: 0.9955\n",
      "Epoch 10/10\n",
      "53999/53999 [==============================] - 33s 618us/step - loss: 0.0183 - acc: 0.9954\n",
      " 3320/53999 [>.............................] - ETA: 27s - loss: 0.0172 - acc: 0.9954Epoch 10/10\n",
      "53999/53999 [==============================] - 34s 622us/step - loss: 0.0177 - acc: 0.9955\n",
      "43720/53999 [=======================>......] - ETA: 6s - loss: 0.0184 - acc: 0.9952Epoch 10/10\n",
      "53999/53999 [==============================] - 33s 618us/step - loss: 0.0188 - acc: 0.9950\n",
      "Epoch 10/10\n",
      "53999/53999 [==============================] - 33s 617us/step - loss: 0.0176 - acc: 0.9955\n",
      "Epoch 10/10\n",
      "53999/53999 [==============================] - 33s 616us/step - loss: 0.0184 - acc: 0.9953\n",
      "13290/53999 [======>.......................] - ETA: 24s - loss: 0.0167 - acc: 0.9958Epoch 10/10\n",
      "53999/53999 [==============================] - 32s 595us/step - loss: 0.0179 - acc: 0.9955\n",
      "6000/6000 [==============================] - 1s 244us/steploss: 0.0169 - acc: 0.99\n",
      "43330/53999 [=======================>......] - ETA: 6s - loss: 0.0171 - acc: 0.9955Epoch 1/10\n",
      "53999/53999 [==============================] - 33s 602us/step - loss: 0.0184 - acc: 0.9953\n",
      "6000/6000 [==============================] - 1s 248us/steploss: 0.0967 - acc: 0.96\n",
      "53999/53999 [==============================] - 33s 613us/step - loss: 0.0183 - acc: 0.9956\n",
      "53999/53999 [==============================] - 33s 603us/step - loss: 0.0171 - acc: 0.9956\n",
      "53999/53999 [==============================] - 33s 618us/step - loss: 0.0183 - acc: 0.9955\n",
      "53999/53999 [==============================] - 33s 611us/step - loss: 0.0192 - acc: 0.9952\n",
      "6000/6000 [==============================] - 1s 245us/steploss: 0.0853 - acc: 0.97\n",
      "6000/6000 [==============================] - 1s 221us/steposs: 0.0172 - acc: 0.\n",
      "6000/6000 [==============================] - 1s 217us/steposs: 0.0171 - acc: 0.99\n",
      "6000/6000 [==============================] - 1s 177us/steploss: 0.0774 - acc: 0.97\n",
      "53999/53999 [==============================] - 33s 606us/step - loss: 0.0171 - acc: 0.9955\n",
      "6000/6000 [==============================] - 1s 123us/steploss: 0.0723 - acc: 0.97\n",
      "15210/53999 [=======>......................] - ETA: 19s - loss: 0.0672 - acc: 0.9772Epoch 1/10\n",
      "53999/53999 [==============================] - 31s 565us/step - loss: 0.0168 - acc: 0.9958\n",
      "6000/6000 [==============================] - 1s 112us/steploss: 0.0627 - acc: 0.97\n",
      "53999/53999 [==============================] - 18s 327us/step - loss: 0.0477 - acc: 0.9844\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 14s 263us/step - loss: 0.0485 - acc: 0.9844\n",
      "Epoch 2/10\n",
      "53999/53999 [==============================] - 14s 258us/step - loss: 0.0313 - acc: 0.9905\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 14s 262us/step - loss: 0.0324 - acc: 0.9902\n",
      "17230/53999 [========>.....................] - ETA: 9s - loss: 0.0252 - acc: 0.9926Epoch 3/10\n",
      "53999/53999 [==============================] - 14s 261us/step - loss: 0.0269 - acc: 0.9921\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 14s 263us/step - loss: 0.0284 - acc: 0.9920\n",
      "Epoch 4/10\n",
      "53999/53999 [==============================] - 14s 254us/step - loss: 0.0241 - acc: 0.9931\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 14s 257us/step - loss: 0.0248 - acc: 0.9929\n",
      "Epoch 5/10\n",
      "53999/53999 [==============================] - 14s 253us/step - loss: 0.0227 - acc: 0.9939\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 14s 255us/step - loss: 0.0232 - acc: 0.9937\n",
      "Epoch 6/10\n",
      "53999/53999 [==============================] - 14s 251us/step - loss: 0.0206 - acc: 0.9944\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 14s 251us/step - loss: 0.0212 - acc: 0.9944\n",
      "Epoch 7/10\n",
      "53999/53999 [==============================] - 13s 243us/step - loss: 0.0202 - acc: 0.9947\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 13s 247us/step - loss: 0.0203 - acc: 0.9947\n",
      "Epoch 8/10\n",
      "53999/53999 [==============================] - 13s 247us/step - loss: 0.0191 - acc: 0.9950\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 13s 249us/step - loss: 0.0192 - acc: 0.9949\n",
      "Epoch 9/10\n",
      "53999/53999 [==============================] - 14s 250us/step - loss: 0.0190 - acc: 0.9953\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 14s 252us/step - loss: 0.0198 - acc: 0.9950\n",
      "Epoch 10/10\n",
      "53999/53999 [==============================] - 13s 248us/step - loss: 0.0189 - acc: 0.9954\n",
      "6000/6000 [==============================] - 1s 102us/steposs: 0.0173 - acc: 0.\n",
      "54000/54000 [==============================] - 13s 235us/step - loss: 0.0171 - acc: 0.9955\n",
      "5999/5999 [==============================] - 1s 86us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "def build_classifier():\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units = 100, kernel_initializer = 'uniform', activation = 'relu', input_dim = 784))\n",
    "    classifier.add(Dense(units = 100, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 10, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier, batch_size = 10, epochs = 10)\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10, n_jobs = -1)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "59999/59999 [==============================] - 19s 322us/step - loss: 0.0475 - acc: 0.9847\n",
      "Epoch 2/5\n",
      "59999/59999 [==============================] - 18s 306us/step - loss: 0.0325 - acc: 0.9904\n",
      "Epoch 3/5\n",
      "59999/59999 [==============================] - 18s 298us/step - loss: 0.0277 - acc: 0.9923\n",
      "Epoch 4/5\n",
      "59999/59999 [==============================] - 18s 302us/step - loss: 0.0247 - acc: 0.9934\n",
      "Epoch 5/5\n",
      "59999/59999 [==============================] - 18s 302us/step - loss: 0.0223 - acc: 0.9939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1a344ccbe0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(units = 100, kernel_initializer = 'uniform', activation = 'relu', input_dim = 784))\n",
    "classifier.add(Dense(units = 100, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dense(units = 10, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "classifier.fit(X_train, y_train, batch_size = 10, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = pd.read_csv('test_mnist_kaggle.csv')\n",
    "#X_test = dataset_test.iloc[:, 1:].values\n",
    "X_test = dataset_test.values\n",
    "#y_test = dataset_test.iloc[:, 0].values\n",
    "#y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "#cm = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#onehotencoder_test = OneHotEncoder(categorical_features = [0])\n",
    "#y_test = onehotencoder_test.fit_transform(y_test).toarray()\n",
    "y_pred = classifier.predict(X_test)\n",
    "#y_pred = (y_pred > 0.5)\n",
    "result = np.argmax(y_pred, axis=1)\n",
    "result = result.reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(result)\n",
    "df.to_csv(\"kaggle_result.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [0],\n",
       "       [9],\n",
       "       ...,\n",
       "       [3],\n",
       "       [9],\n",
       "       [2]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_first_diagonal = sum(cm[i][i] for i in range(10))\n",
    "print(sum_first_diagonal)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 448.77778,
   "position": {
    "height": "40px",
    "left": "711px",
    "right": "20px",
    "top": "0px",
    "width": "654px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
